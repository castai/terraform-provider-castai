---
page_title: "castai_workload_scaling_policy Resource - terraform-provider-castai"
subcategory: ""
description: |-
  Manage workload scaling policy. Scaling policy reference https://docs.cast.ai/docs/woop-scaling-policies
---

# castai_workload_scaling_policy (Resource)

Manage workload scaling policy. Scaling policy [reference](https://docs.cast.ai/docs/woop-scaling-policies)

Scaling policies allow you to manage all your workloads centrally. You can apply the same settings to multiple workloads
simultaneously or create custom policies with different settings and apply them to multiple workloads.

## Example Usage

```terraform
resource "castai_workload_scaling_policy" "services" {
  name              = "services"
  cluster_id        = castai_gke_cluster.dev.id
  apply_type        = "IMMEDIATE"
  management_option = "MANAGED"
  cpu {
    function                 = "QUANTILE"
    overhead                 = 0.15
    apply_threshold          = 0.1
    args                     = ["0.9"]
    look_back_period_seconds = 172800
    min                      = 0.1
    max                      = 1
  }
  memory {
    function        = "MAX"
    overhead        = 0.35
    apply_threshold = 0.2
    limit {
      type       = "MULTIPLIER"
      multiplier = 1.5
    }
    management_option = "READ_ONLY"
  }
  startup {
    period_seconds = 240
  }
  downscaling {
    apply_type = "DEFERRED"
  }
  memory_event {
    apply_type = "IMMEDIATE"
  }
  anti_affinity {
    consider_anti_affinity = false
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `apply_type` (String) Recommendation apply type.
	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
- `cluster_id` (String) CAST AI cluster id
- `cpu` (Block List, Min: 1, Max: 1) (see [below for nested schema](#nestedblock--cpu))
- `management_option` (String) Defines possible options for workload management.
	- READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	- MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
- `memory` (Block List, Min: 1, Max: 1) (see [below for nested schema](#nestedblock--memory))
- `name` (String) Scaling policy name

### Optional

- `anti_affinity` (Block List, Max: 1) (see [below for nested schema](#nestedblock--anti_affinity))
- `downscaling` (Block List, Max: 1) (see [below for nested schema](#nestedblock--downscaling))
- `memory_event` (Block List, Max: 1) (see [below for nested schema](#nestedblock--memory_event))
- `startup` (Block List, Max: 1) (see [below for nested schema](#nestedblock--startup))
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))

### Read-Only

- `id` (String) The ID of this resource.

<a id="nestedblock--cpu"></a>
### Nested Schema for `cpu`

Optional:

- `apply_threshold` (Number) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
- `args` (List of String) The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
- `function` (String) The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
- `limit` (Block List, Max: 1) Resource limit settings (see [below for nested schema](#nestedblock--cpu--limit))
- `look_back_period_seconds` (Number) The look back period in seconds for the recommendation.
- `management_option` (String) Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
- `max` (Number) Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
- `min` (Number) Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
- `overhead` (Number) Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation

<a id="nestedblock--cpu--limit"></a>
### Nested Schema for `cpu.limit`

Required:

- `type` (String) Defines limit strategy type.
	- NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	- MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.

Optional:

- `multiplier` (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.



<a id="nestedblock--memory"></a>
### Nested Schema for `memory`

Optional:

- `apply_threshold` (Number) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
- `args` (List of String) The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
- `function` (String) The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
- `limit` (Block List, Max: 1) Resource limit settings (see [below for nested schema](#nestedblock--memory--limit))
- `look_back_period_seconds` (Number) The look back period in seconds for the recommendation.
- `management_option` (String) Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
- `max` (Number) Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
- `min` (Number) Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
- `overhead` (Number) Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation

<a id="nestedblock--memory--limit"></a>
### Nested Schema for `memory.limit`

Required:

- `type` (String) Defines limit strategy type.
	- NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	- MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.

Optional:

- `multiplier` (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.



<a id="nestedblock--anti_affinity"></a>
### Nested Schema for `anti_affinity`

Optional:

- `consider_anti_affinity` (Boolean) Defines if anti-affinity should be considered when scaling the workload.
	If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.


<a id="nestedblock--downscaling"></a>
### Nested Schema for `downscaling`

Optional:

- `apply_type` (String) Defines the apply type to be used when downscaling.
	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)


<a id="nestedblock--memory_event"></a>
### Nested Schema for `memory_event`

Optional:

- `apply_type` (String) Defines the apply type to be used when applying recommendation for memory related event.
	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)


<a id="nestedblock--startup"></a>
### Nested Schema for `startup`

Optional:

- `period_seconds` (Number) Defines the duration (in seconds) during which elevated resource usage is expected at startup.
When set, recommendations will be adjusted to disregard resource spikes within this period.
If not specified, the workload will receive standard recommendations without startup considerations.


<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String)
- `delete` (String)
- `read` (String)
- `update` (String)


## Importing
You can use the `terraform import` command to import existing scaling policy to Terraform state.

To import a resource, first write a resource block for it in your configuration, establishing the name by which
it will be known to Terraform:
```hcl
resource "castai_workload_scaling_policy" "services" {
  # ...
}
```

Now terraform import can be run to attach an existing scaling policy to this resource:
```shell
$ terraform import castai_workload_scaling_policy.services <cluster_id>/services
```

If you are using CAST AI Terraform modules, import command will be slightly different:
```shell
$ terraform import 'module.castai-eks-cluster.castai_workload_scaling_policy.this["services"]' <cluster_id>/services
```